{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DFL_Colab_1-0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BDg_jiQ9adQe",
        "JuVn21kt40Gw",
        "hqwOlJG4MdLC",
        "tUNVcbujhm00",
        "WTuyUxgdLA13",
        "avAcSL_uvtq_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felipe3DArtist/OpenColorIO-Configs/blob/master/DFL_Colab_1-0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# Welcome to DFL-Colab!\n",
        "\n",
        "This is an adapted version of the DFL for Google Colab.\n",
        "Works only with DFL 1.0\n",
        "\n",
        "# Overview\n",
        "*   Extractor works in full functionality.\n",
        "*   Training can work without preview.\n",
        "*   Converter works in full functionality.\n",
        "*   You can import/export workspace with your Google Drive.\n",
        "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
        "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode, after 11 hours from the start of the session.\n",
        "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg_jiQ9adQe"
      },
      "source": [
        "# Check GPU\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
        "*   Here you can check the model of GPU before using DeepFaceLab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJe71S6gbzt3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "# Clone Github repository and install requirements\n",
        "\n",
        "* Clone Github repository or pull updates\n",
        "* Requirements install is automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-f2WqT4fLK",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c462872-24de-4225-d844-feead6337bca"
      },
      "source": [
        "#@title Clone or pull DeepFaceLab from Github\n",
        "\n",
        "Mode = \"clone\" #@param [\"clone\", \"pull\"]\n",
        "\n",
        "from pathlib import Path\n",
        "if (Mode == \"clone\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git --branch DFL-1.0\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "!apt-get install cuda-10-0\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/pretrain-CelebA/pretrain_CelebA.zip' -O pretrain_CelebA.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_CelebA.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_CelebA.zip\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepFaceLab'...\n",
            "remote: Enumerating objects: 7359, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 7359 (delta 46), reused 76 (delta 32), pack-reused 7248\u001b[K\n",
            "Receiving objects: 100% (7359/7359), 815.45 MiB | 21.23 MiB/s, done.\n",
            "Resolving deltas: 100% (4722/4722), done.\n",
            "Checking out files: 100% (153/153), done.\n",
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git (from -r /content/DeepFaceLab/requirements-colab.txt (line 10))\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-zw11x4xr\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-zw11x4xr\n",
            "Collecting numpy==1.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/4b/55cfbfd3e5e85016eeef9f21c0ec809d978706a0d60b62cc28aeec8c792f/numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
            "\u001b[K     |████████████████████████████████| 20.3MB 1.7MB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 42.3MB/s \n",
            "\u001b[?25hCollecting Keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 41.3MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/52/61b9619a7a95a8d809515f68f1441224a07ce1873fd3af5e662851014a55/opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 2.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/65/8dc8fc4a263a24f7ad935b72ad35e72ba381cb9e175b6a5fe086c85f17a7/tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0MB)\n",
            "\u001b[K     |████████████████████████████████| 345.0MB 38kB/s \n",
            "\u001b[?25hCollecting plaidml-keras==0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/17/34/4102261e3d8867c31bae9f4def5d7e700fc25fff232fa1780040e8ed79b0/plaidml_keras-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 7)) (0.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 8)) (4.41.1)\n",
            "Collecting ffmpeg-python==0.1.17\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/10/330cbc8e63d072d40413f4d470444a6a1e8c8c6a80b2a4ac302d1252ca1b/ffmpeg_python-0.1.17-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.9.0->-r /content/DeepFaceLab/requirements-colab.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.3.3)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.36.2)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (1.1.0)\n",
            "Collecting plaidml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/0a/a190acece24f69b38ce1d07ccfc6ccb3336cbf7e81a70d96c37f193eb30a/plaidml-0.7.0-py2.py3-none-manylinux1_x86_64.whl (22.0MB)\n",
            "\u001b[K     |████████████████████████████████| 22.0MB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.1.17->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.16.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (3.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (56.0.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from plaidml->plaidml-keras==0.5.0->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.14.5)\n",
            "Collecting enum34>=1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (3.10.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->plaidml->plaidml-keras==0.5.0->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.20)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (3.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=ded7876b7b1a3ae353759ccaea7bc156db3ee51d25d91ea975d8bbda6b25dd49\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-madrf_bx/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, h5py, keras-applications, Keras, opencv-python, mock, tensorflow-estimator, tensorboard, tensorflow-gpu, enum34, plaidml, plaidml-keras, ffmpeg-python, keras-contrib\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed Keras-2.2.4 enum34-1.1.10 ffmpeg-python-0.1.17 h5py-2.9.0 keras-applications-1.0.8 keras-contrib-2.0.8 mock-4.0.3 numpy-1.17.0 opencv-python-4.1.0.25 plaidml-0.7.0 plaidml-keras-0.5.0 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.4.8)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.17.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-image\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "Successfully installed scikit-image-0.18.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "#Manage workspace\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export workspace or individual data, like model files with Google Drive\n",
        "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
        "*   You can clear all workspace or delete part of it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4w_sUzgOQmL",
        "cellView": "form"
      },
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3WfuwoNXqC",
        "cellView": "form"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"models\", \"result video\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hIvJtxwTGcb"
      },
      "source": [
        "#@title Import from URL{ form-width: \"30%\", display-mode: \"form\" }\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"download to content/workspace\" #@param [\"unzip to content\", \"unzip to content/workspace\", \"unzip to content/workspace/data_src\", \"unzip to content/workspace/data_src/aligned\", \"unzip to content/workspace/data_dst\", \"unzip to content/workspace/data_dst/aligned\", \"unzip to content/workspace/model\", \"download to content/workspace\"]\n",
        "\n",
        "import urllib\n",
        "from pathlib import Path\n",
        "\n",
        "def unzip(zip_path, dest_path):\n",
        "\n",
        "    \n",
        "  unzip_cmd = \" unzip -q \" + zip_path + \" -d \"+dest_path\n",
        "  !$unzip_cmd  \n",
        "  rm_cmd = \"rm \"+dest_path + url_path.name\n",
        "  !$rm_cmd\n",
        "  print(\"Unziped!\")\n",
        "  \n",
        "\n",
        "if Mode == \"unzip to content\":\n",
        "  dest_path = \"/content/\"\n",
        "elif Mode == \"unzip to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src\":\n",
        "  dest_path = \"/content/workspace/data_src/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src/aligned\":\n",
        "  dest_path = \"/content/workspace/data_src/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst\":\n",
        "  dest_path = \"/content/workspace/data_dst/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst/aligned\":\n",
        "  dest_path = \"/content/workspace/data_dst/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/model\":\n",
        "  dest_path = \"/content/workspace/model/\"\n",
        "elif Mode == \"download to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  cmd = \"mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
        "  !$cmd\n",
        "\n",
        "url_path = Path(URL)\n",
        "urllib.request.urlretrieve ( URL, dest_path + url_path.name )\n",
        "\n",
        "if (url_path.suffix == \".zip\") and (Mode!=\"download to content/workspace\"):\n",
        "  unzip(dest_path + url_path.name, dest_path)\n",
        "\n",
        "  \n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1sc7rxNKLO",
        "cellView": "form"
      },
      "source": [
        "#@title Export to URL\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
        "\n",
        "cmd_zip = \"zip -r -q \"\n",
        "\n",
        "def run_cmd(zip_path, curl_url):\n",
        "  cmd_zip = \"zip -r -q \"+zip_path\n",
        "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
        "  !$cmd_zip\n",
        "  !$cmd_curl\n",
        "\n",
        "\n",
        "if Mode == \"upload workspace\":\n",
        "  %cd \"/content\"\n",
        "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
        "elif Mode == \"upload data_src\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
        "elif Mode == \"upload data_dst\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
        "elif Mode == \"upload data_src aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
        "elif Mode == \"upload data_dst aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
        "elif Mode == \"upload merged\":\n",
        "  %cd \"/content/workspace/data_dst\"\n",
        "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
        "elif Mode == \"upload model\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
        "elif Mode == \"upload result video\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
        "  \n",
        "  \n",
        "!rm *.zip\n",
        "\n",
        "%cd \"/content\"\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta6ue_UGMkki",
        "cellView": "form"
      },
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\" \n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"  \n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged\"\n",
        "  \n",
        "!$cmd\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "# Extract, sorting and faceset tools\n",
        "* Extract frames for SRC or DST video.\n",
        "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
        "* Detect and align faces with one of detectors. (S3FD - recommended). If you need, you can get frames with debug landmarks.\n",
        "* Options \"S3FD (Mark only)\" and \"S3FD (Extract unaligned)\" are needed for the AVATAR model. Before using, read the guide in the DeepFaceLab repository.\n",
        "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
        "* You can enhance your facesets with DFL FacesetEnhancer. Enhanced images will replace yours in \"aligned\" directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJEbz5Nhot0",
        "cellView": "form"
      },
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "  \n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmPo0s2lTil",
        "cellView": "form"
      },
      "source": [
        "#@title Denoise frames\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmq0Sj2bmq7d",
        "cellView": "form"
      },
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (Mark only)\", \"S3FD (Extract unaligned)\", \"MT\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "facetype = None\n",
        "\n",
        "if Detector == \"S3FD\":\n",
        "  detect_type = \"s3fd\"\n",
        "elif Detector == \"S3FD (Mark only)\":\n",
        "  detect_type = \"s3fd\"\n",
        "  facetype = \"mark_only\"\n",
        "elif Detector == \"S3FD (Extract unaligned)\":\n",
        "  detect_type = \"s3fd\"\n",
        "  facetype = \"full_face_no_align\"\n",
        "elif Detector == \"MT\":\n",
        "  detect_type = \"mt\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_align = folder+\"/aligned\"\n",
        "debug_folder = folder_align+\"/debug\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_align\n",
        "\n",
        "if Debug:\n",
        "  cmd+= \" --debug-dir \"+debug_folder\n",
        "\n",
        "cmd+=\" --detector \"+detect_type\n",
        "  \n",
        "if facetype:\n",
        "  cmd+=\" --face-type \"+facetype\n",
        "  \n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRNxUFE6p6Eu",
        "cellView": "form"
      },
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"absdiff\" #@param [\"absdiff\",\"hist\", \"hist-dissim\", \"face-yaw\", \"face-pitch\", \"vggface\", \"blur\", \"final\", \"final-no-blur\"]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MbnVDyXkP7",
        "cellView": "form"
      },
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "# Train model\n",
        "\n",
        "* Choose your model type, but SAEHD is recommend for everyone\n",
        "* Set model options on output field\n",
        "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
        "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
        "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* Also, you can export your workspace manually in \"Manage workspace\" block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Kya-PJLDhv",
        "cellView": "form"
      },
      "source": [
        "#@title Training\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"SAE\", \"Quick96\", \"H128\", \"LIAEF128\", \"DF\", \"AVATAR\", \"DEV_FANSEG\"]\n",
        "Backup_every_hour = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  if not os.path.exists('workspace.zip'):\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    !zip -r -q workspace.zip workspace\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exist!\")\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(3600)\n",
        "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "    \n",
        "cmd = \"DeepFaceLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain --model-dir workspace/model --model \"+Model\n",
        "  \n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "# Convert frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Y8K22Sv9Gn",
        "cellView": "form"
      },
      "source": [
        "#@title Convert\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"SAE\", \"Quick96\", \"H128\", \"LIAEF128\", \"DF\", \"AVATAR\" ]\n",
        "\n",
        "if Model == \"AVATAR\":  \n",
        "  cmd = \"DeepFaceLab/main.py convert --input-dir workspace/data_dst/aligned --output-dir workspace/data_dst/merged --model-dir workspace/model --model \"+Model\n",
        "else:\n",
        "  cmd = \"DeepFaceLab/main.py convert --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNeGfiZpxlnz",
        "cellView": "form"
      },
      "source": [
        "#@title Get result video and copy to Drive \n",
        "\n",
        "!python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4\n",
        "!cp /content/workspace/result.mp4 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}